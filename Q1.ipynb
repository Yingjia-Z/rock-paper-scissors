{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "odj1Coq5H080"
      },
      "source": [
        "#@title ##### License { display-mode: \"form\" }\n",
        "# Copyright 2019 DeepMind Technologies Ltd. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOOzDGYAZcW3"
      },
      "source": [
        "# OpenSpiel: RRPS Example\n",
        "\n",
        "* This Colab gets you started with installing OpenSpiel and its dependencies.\n",
        "* OpenSpiel is a framework for reinforcement learning in games.\n",
        "* For a longer intro to OpenSpiel, see [the tutorial video](https://www.youtube.com/watch?v=8NCPqtPwlFQ), [documentation](https://openspiel.readthedocs.io/en/latest/), or [API reference](https://openspiel.readthedocs.io/en/latest/api_reference.html).\n",
        "* This colab also includes examples of how to get started with the Roshambo/RRPS environment and bots. It is based on [roshambo_population_example.py](https://github.com/google-deepmind/open_spiel/blob/master/open_spiel/python/examples/roshambo_population_example.py)\n",
        "* For more info on Roshambo, see the [RRPS benchmark paper](https://openreview.net/pdf?id=gQnJ7ODIAx)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC6kQBzWahEF"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2_Vbijh4FlZ"
      },
      "source": [
        "Install OpenSpiel via pip:\n",
        "\n",
        "Note that if you are not using a colab, then you would use\n",
        "python3 -m pip install open_spiel\n",
        "Additional information about installing OpenSpiel can be found at the links above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQc12Xrn4CXU"
      },
      "source": [
        "!pip install --upgrade open_spiel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUtlXZ8FBnAL"
      },
      "source": [
        "# Simple example of OpenSpiel API: uniform random trajectory on Tic-Tac-Toe\n",
        "\n",
        "This example is not used for RRPS, but it shows how to load a game in OpenSpiel, how to access a game state, and implements a random strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewMXCaUw8d9Q"
      },
      "source": [
        "import numpy as np\n",
        "import pyspiel\n",
        "\n",
        "game = pyspiel.load_game(\"tic_tac_toe\")\n",
        "state = game.new_initial_state()\n",
        "\n",
        "while not state.is_terminal():\n",
        "  state.apply_action(np.random.choice(state.legal_actions()))\n",
        "  print(str(state) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with RRPS\n"
      ],
      "metadata": {
        "id": "O2hLkPIHLjjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "\n",
        "from open_spiel.python import rl_agent\n",
        "from open_spiel.python import rl_environment\n",
        "import pyspiel\n"
      ],
      "metadata": {
        "id": "iF2eZXwmMJsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some helper classes and functions.\n",
        "# DO NOT CHANGE.\n",
        "\n",
        "class BotAgent(rl_agent.AbstractAgent):\n",
        "  \"\"\"Agent class that wraps a bot.\n",
        "\n",
        "  Note, the environment must include the OpenSpiel state in its observations,\n",
        "  which means it must have been created with use_full_state=True.\n",
        "\n",
        "  This is a simple wrapper that lets the RPS bots be interpreted as agents under\n",
        "  the RL API.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_actions, bot, name=\"bot_agent\"):\n",
        "    assert num_actions > 0\n",
        "    self._bot = bot\n",
        "    self._num_actions = num_actions\n",
        "\n",
        "  def restart(self):\n",
        "    self._bot.restart()\n",
        "\n",
        "  def step(self, time_step, is_evaluation=False):\n",
        "    # If it is the end of the episode, don't select an action.\n",
        "    if time_step.last():\n",
        "      return\n",
        "    _, state = pyspiel.deserialize_game_and_state(\n",
        "        time_step.observations[\"serialized_state\"])\n",
        "    action = self._bot.step(state)\n",
        "    probs = np.zeros(self._num_actions)\n",
        "    probs[action] = 1.0\n",
        "    return rl_agent.StepOutput(action=action, probs=probs)\n",
        "\n",
        "\n",
        "#  We will use this function to evaluate the agents. Do not change.\n",
        "\n",
        "def eval_agents(env, agents, num_players, num_episodes, verbose=False):\n",
        "  \"\"\"Evaluate the agent.\n",
        "\n",
        "  Runs a number of episodes and returns the average returns for each agent as\n",
        "  a numpy array.\n",
        "\n",
        "  Arguments:\n",
        "    env: the RL environment,\n",
        "    agents: a list of agents (size 2),\n",
        "    num_players: number of players in the game (for RRPS, this is 2),\n",
        "    num_episodes: number of evaluation episodes to run.\n",
        "    verbose: whether to print updates after each episode.\n",
        "  \"\"\"\n",
        "  sum_episode_rewards = np.zeros(num_players)\n",
        "  for ep in range(num_episodes):\n",
        "    for agent in agents:\n",
        "      # Bots need to be restarted at the start of the episode.\n",
        "      if hasattr(agent, \"restart\"):\n",
        "        agent.restart()\n",
        "    time_step = env.reset()\n",
        "    episode_rewards = np.zeros(num_players)\n",
        "    while not time_step.last():\n",
        "      agents_output = [\n",
        "          agent.step(time_step, is_evaluation=True) for agent in agents\n",
        "      ]\n",
        "      action_list = [agent_output.action for agent_output in agents_output]\n",
        "      time_step = env.step(action_list)\n",
        "      episode_rewards += time_step.rewards\n",
        "    sum_episode_rewards += episode_rewards\n",
        "    if verbose:\n",
        "      print(f\"Finished episode {ep}, \"\n",
        "            + f\"avg returns: {sum_episode_rewards / (ep+1)}\")\n",
        "\n",
        "  return sum_episode_rewards / num_episodes\n",
        "\n",
        "\n",
        "def print_roshambo_bot_names_and_ids(roshambo_bot_names):\n",
        "  print(\"Roshambo bot population:\")\n",
        "  for i in range(len(roshambo_bot_names)):\n",
        "    print(f\"{i}: {roshambo_bot_names[i]}\")\n",
        "\n",
        "def create_roshambo_bot_agent(player_id, num_actions, bot_names, pop_id):\n",
        "  name = bot_names[pop_id]\n",
        "  # Creates an OpenSpiel bot with the default number of throws\n",
        "  # (pyspiel.ROSHAMBO_NUM_THROWS). To create one for a different number of\n",
        "  # throws per episode, add the number as the third argument here.\n",
        "  bot = pyspiel.make_roshambo_bot(player_id, name)\n",
        "  return BotAgent(num_actions, bot, name=name)\n"
      ],
      "metadata": {
        "id": "4SavmNn1MG-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The following functions are used to load the bots from the original RRPS competition."
      ],
      "metadata": {
        "id": "-FZlLow5w5da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic info and initialize the population\n",
        "\n",
        "# print(pyspiel.ROSHAMBO_NUM_BOTS)    # 43 bots\n",
        "# print(pyspiel.ROSHAMBO_NUM_THROWS)  # 1000 steps per episode\n",
        "\n",
        "# The recall is how many of the most recent actions are presented to the RL\n",
        "# agents as part of their observations. Note: this is just for the RL agents\n",
        "# like DQN etc... every bot has access to the full history.\n",
        "RECALL = 20\n",
        "\n",
        "# The population of 43 bots. See the RRPS paper for high-level descriptions of\n",
        "# what each bot does.\n",
        "\n",
        "print(\"Loading bot population...\")\n",
        "pop_size = pyspiel.ROSHAMBO_NUM_BOTS\n",
        "print(f\"Population size: {pop_size}\")\n",
        "roshambo_bot_names = pyspiel.roshambo_bot_names()\n",
        "roshambo_bot_names.sort()\n",
        "print_roshambo_bot_names_and_ids(roshambo_bot_names)\n",
        "\n",
        "bot_id = 0\n",
        "roshambo_bot_ids = {}\n",
        "for name in roshambo_bot_names:\n",
        "  roshambo_bot_ids[name] = bot_id\n",
        "  bot_id += 1\n"
      ],
      "metadata": {
        "id": "Zimu2jMiNuYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example showing how to load to agents from the RRPS bot population and evalute them against each other."
      ],
      "metadata": {
        "id": "6_qAMW6p5btS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: create an RL environment, and two agents from the bot population and\n",
        "# evaluate these two agents head-to-head.\n",
        "\n",
        "# Note that the include_full_state variable has to be enabled because the\n",
        "# BotAgent needs access to the full state.\n",
        "env = rl_environment.Environment(\n",
        "    \"repeated_game(stage_game=matrix_rps(),num_repetitions=\" +\n",
        "    f\"{pyspiel.ROSHAMBO_NUM_THROWS},\" +\n",
        "    f\"recall={RECALL})\",\n",
        "    include_full_state=True)\n",
        "num_players = 2\n",
        "num_actions = env.action_spec()[\"num_actions\"]\n",
        "# Learning agents might need this:\n",
        "# info_state_size = env.observation_spec()[\"info_state\"][0]\n",
        "\n",
        "# Create two bot agents\n",
        "p0_pop_id = 0   # actr_lag2_decay\n",
        "p1_pop_id = 1   # adddriftbot2\n",
        "agents = [\n",
        "    create_roshambo_bot_agent(0, num_actions, roshambo_bot_names, p0_pop_id),\n",
        "    create_roshambo_bot_agent(1, num_actions, roshambo_bot_names, p1_pop_id)\n",
        "]\n",
        "\n",
        "print(\"Starting eval run.\")\n",
        "avg_eval_returns = eval_agents(env, agents, num_players, 10, verbose=True)\n",
        "\n",
        "print(\"Avg return \", avg_eval_returns)"
      ],
      "metadata": {
        "id": "e-u0LlkiOCD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic Template for an RL agent\n",
        "\n",
        "Below is a template of a basic RL agent to get you started. You will be implementing the step() function."
      ],
      "metadata": {
        "id": "BKedmD2G3Axh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Template to get you started. Pick one of these to implement as your starting\n",
        "# point.\n",
        "\n",
        "# Template : Basic RL agent.\n",
        "#\n",
        "#\n",
        "class MyAgent(rl_agent.AbstractAgent):\n",
        "  \"\"\"Agent class that learns to play RRPS.\n",
        "\n",
        "  You fill this in to create your RRPS agent.\n",
        "\n",
        "  See the superclass for more info: https://github.com/google-deepmind/open_spiel/blob/master/open_spiel/python/rl_agent.py\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_actions, name=\"bot_agent\"):\n",
        "    assert num_actions > 0\n",
        "    self._num_actions = num_actions  # 3\n",
        "\n",
        "  def step(self, time_step, is_evaluation=False):\n",
        "    # If it is the end of the episode, don't select an action.\n",
        "    if time_step.last():\n",
        "      return\n",
        "    # Note: If the environment was created with include_full_state=True, then\n",
        "    # game and state can be obtained as follows:\n",
        "\n",
        "    game, state = pyspiel.deserialize_game_and_state(time_step.observations[\"serialized_state\"])\n",
        "\n",
        "    # A useful piece of information is the history (previous actions taken by agents).\n",
        "    # You can access this by state.history()\n",
        "\n",
        "    # Do something here that selects an action and computes a policy\n",
        "    # distribution in probs.\n",
        "    if len(state.history())==0:\n",
        "      action = 0\n",
        "    else:\n",
        "      action = state.history()[-1]\n",
        "    probs = np.ones(self._num_actions) / self._num_actions\n",
        "    return rl_agent.StepOutput(action=action, probs=probs)\n",
        "\n"
      ],
      "metadata": {
        "id": "kpbyfKe2SV1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A short example to show how to evaluate your agent againt an RRPS bot."
      ],
      "metadata": {
        "id": "63PMnhw95GQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just trying an example out.\n",
        "\n",
        "my_agent = MyAgent(3, name=\"kate_agent\")\n",
        "print(my_agent._num_actions)\n",
        "\n",
        "\n",
        "p1_pop_id = 1   # adddriftbot2\n",
        "agents = [\n",
        "    my_agent,\n",
        "    create_roshambo_bot_agent(1, num_actions, roshambo_bot_names, p1_pop_id)\n",
        "]\n",
        "\n",
        "\n",
        "print(\"Starting eval run.\")\n",
        "avg_eval_returns = eval_agents(env, agents, num_players, 4, verbose=True)\n",
        "\n",
        "print(\"Avg return \", avg_eval_returns)"
      ],
      "metadata": {
        "id": "gtjPe7O4as2V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}